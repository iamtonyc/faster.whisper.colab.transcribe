# -*- coding: utf-8 -*-
"""faster-whisper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11fVHrinjfJxuHBxTsoyyF5uTdLc715eZ
"""

!apt install libcublas11

!pip install faster-whisper

from faster_whisper import WhisperModel
import os
from google.colab import files

model_size = "large-v2" # tiny, base, small, medium, large, large-v2, large-v3
mode = "normal" # normal 一般, timeline 加入時間軸, subtitle 產生成字幕檔格式

# Run on GPU with FP16
model = WhisperModel(model_size, device="cuda", compute_type="float16")

# 設定檔案路徑
#audio_path = "/content/short.m4a" # 替換成你的檔案名稱
audio_path = "short.m4a" # 替換成你的檔案名稱

segments, info = model.transcribe(audio_path, beam_size=5, initial_prompt="繁體")

transcription = ""

# 1 以下為一般版本
if mode == "normal":
  transcription_segments = [segment.text for segment in segments]
  transcription = "，".join(transcription_segments)

# 2 以下為加入時間軸版本
elif mode == "timeline":
  for segment in segments:
    transcription += "[%.2fs -> %.2fs] %s\n" % (segment.start, segment.end, segment.text)

# 3 以下為產生字幕檔的版本
elif mode == "subtitle":
  for i, segment in enumerate(segments, 1):
    start_hours, start_remainder = divmod(segment.start, 3600)
    start_minutes, start_seconds = divmod(start_remainder, 60)
    end_hours, end_remainder = divmod(segment.end, 3600)
    end_minutes, end_seconds = divmod(end_remainder, 60)
    transcription += "%d\n%02d:%02d:%06.3f --> %02d:%02d:%06.3f\n%s\n\n" % (
      i,
      start_hours, start_minutes, start_seconds,
      end_hours, end_minutes, end_seconds,
      segment.text
    )

print(transcription)

# 獲取不帶副檔名的檔案名稱
file_name = os.path.splitext(os.path.basename(audio_path))[0]

# 將結果保存為txt檔案
with open(f"{file_name}.txt", "w") as file:
  file.write(transcription)
  files.download(f"{file_name}.txt")